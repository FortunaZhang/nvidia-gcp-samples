This notebook demonstrate a 3 steps workflow, including Finetune, TRT optimization, Triton Model Server.

Please proceed to [ai_platform_prediction_triton/triton-ngc-caip.ipynb](https://github.com/NVIDIA/nvidia-gcp-samples/tree/master/ai-platform-samples/bert_on_caip/ai_platform_prediction_triton) for further instruction.

## Additional Documentation:

- [AI Platform Prediction: Custom container concepts with Triton Server](https://cloud.google.com/solutions/ai-platform-prediction-custom-container-concepts) by [Kevin Tsai](https://github.com/merlin1649)
- [AI Platform Prediction: Direct model server setup for NVIDIA Triton Inference Server](https://cloud.google.com/solutions/ai-platform-prediction-direct-model-server-nvidia) by [Kevin Tsai](https://github.com/merlin1649)
